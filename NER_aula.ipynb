{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Atividade Named-Entity Recognition (NER)\n",
    "\n",
    "### Desafio\n",
    "\n",
    "Crie a rotina para processamento dos textos, preparando os documentos para respeitar a estrutura proposta para rodar uma rede neural capaz de realizar a atividade de reconhecimento de entidades.\n",
    "\n",
    "Lembre que o resultado deverá ter três colunas (identificador, palavra e tag) como exemplificado na tabela abaixo:\n",
    "\n",
    "| identificador | palavra | tag |\n",
    "|:--:|:--:|:--:|\n",
    "|102|tronco|O|\n",
    "|102|da|O|\n",
    "|102|coronaria|vaso|\n",
    "|102|esquerda|vaso|\n",
    "|102|com|O|\n",
    "|102|trajeto|O|\n",
    "\n",
    "Você deverá considerar as seguintes classes e termos por classe:\n",
    "\n",
    "-   **vaso**:\n",
    "\t- descendente anterior;\n",
    "\t- coronaria direita;\n",
    "\t- coronaria esquerda;\n",
    "\t- circunflexa;\n",
    "\t- primeiro ramo marginal;\n",
    "\t- segundo ramo marginal;\n",
    "\t- terceiro ramo marginal;\n",
    "\t- primeiro ramo diagonal;\n",
    "\t- segundo ramo diagonal;\n",
    "\t- terceiro ramo diagonal;\n",
    "\t- ventricular posterior;\n",
    "\t- arteria diagonalis;\n",
    "\t- descendente posteiror.\n",
    "-   **trajeto**:\n",
    "\t- trajeto intramiocardico;\n",
    "\t- origem;\n",
    "\t- retroaortico;\n",
    "\t- interaortopulmonar;\n",
    "\t- valsalva;\n",
    "\t- seio;\n",
    "\t- sinotubular.\n",
    "-   **placa**:\n",
    "\t- placa;\n",
    "\t- placas;\n",
    "\t- ateromatose.\n",
    "-   **composição**:\n",
    "\t- calcificada;\n",
    "\t- calcificadas;\n",
    "\t- densamente calcificada;\n",
    "\t- densamente calcificadas;\n",
    "\t- densa;\n",
    "\t- densamente calcificado;\n",
    "\t- parcialmente calcificada;\n",
    "\t- predominantemente calcificada;\n",
    "\t- predominantemente calcificadas;\n",
    "\t- mista;\n",
    "\t- mistas;\n",
    "\t- predominantemente nao calcificada;\n",
    "\t- predominantemente não calcificada;\n",
    "\t- parcialmente não calcificada;\n",
    "\t- principalmente calcificada;\n",
    "\t- principalmente não calcificada;\n",
    "\t- principalmente nao calcificada;\n",
    "\t- predominio calcificado;\n",
    "\t- predominio nao calcificado;\n",
    "\t- não calcificada.\n",
    "-   **grau**:\n",
    "\t- sem redução luminal;\n",
    "\t- discreta;\n",
    "\t- irregularidades parietais;\n",
    "\t- irregularidade parietal;\n",
    "\t- menor que 50%;\n",
    "\t- irregularidades luminais;\n",
    "\t- irregularidade luminal;\n",
    "\t- irregularidade;\n",
    "\t- irregularidades;\n",
    "\t- proxima de 50%;\n",
    "\t- proximo de 50%;\n",
    "\t- entre 50 e 70%;\n",
    "\t- 50%;\n",
    "\t- acima de 50%;\n",
    "\t- maior que 50%;\n",
    "\t- ao redor de 50%;\n",
    "\t- cerca de 50%;\n",
    "\t- em torno de 50%;\n",
    "\t- acima de 70%;\n",
    "\t- 70%;\n",
    "\t- cerca de 70%;\n",
    "\t- ao redor de 70%;\n",
    "\t- em torno de 70%;\n",
    "\t- moderada;\n",
    "\t- moderada reducao luminal;\n",
    "\t- reducao luminal moderada;\n",
    "\t- estenose moderada;\n",
    "\t- grau pelo menos moderado;\n",
    "\t- grau moderado;\n",
    "\t- acentuada;\n",
    "\t- suboclusao;\n",
    "\t- reducao luminal critica;\n",
    "\t- estenose critica;\n",
    "\t- oclusao;\n",
    "\t- ocluido;\n",
    "\t- ocluida.\n",
    "-   **modificador V**:\n",
    "\t- modificador V;\n",
    "\t- vulnerabilidade;\n",
    "\t- remodelamento positivo;\n",
    "\t- baixa atenuação;\n",
    "\t- napking ring;\n",
    "\t- anel de guardanapo;\n",
    "\t- spot calcifications;\n",
    "\t- remodelamento arterial positivo.\n",
    "-   **stent**:\n",
    "\t- stent.\n",
    "-   **redução stent**:\n",
    "\t- hiperplasia neointimal;\n",
    "\t- neointimal;\n",
    "\t- proliferação neointimal.\n",
    "-   **enxerto**:\n",
    "\t- enxerto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resolução\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "df = pd.read_excel('https://github.com/pgiaeinstein/ner-aula/raw/master/data_full.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_vaso = re.compile(r\"(descendente anterior|descendente posterior|coronaria (esquerda|direita)|circunflexa|ventricular posterior|arteria diagonalis|((primeiro|segundo|terceiro|quarto)(\\se\\s|\\s))+(ramos?)?\\s?(diagon(al|ais)?|margin(al|ais)?)?)\")\n",
    "reg_trajeto = re.compile(r\"(trajeto intramiocardico|retroaórtico|interaortopulmonar|valssalva|sinotubular|seio)\")\n",
    "reg_placa = re.compile(r\"(placas?|ateromatose)\")\n",
    "reg_desc_placa = re.compile(r\"((predominantemente nao |nao |parcialmente |parcialmente nao |predominantemente |principalmente |principalmente nao |densamente )?calcificadas?|mistas?|predominio calcificado|predominio nao calcificado|densamente calcificado|densa)\")\n",
    "reg_oclusao = re.compile(r\"(oclusao|suboclusao|acentuada|\\b70%?\\b|\\b50%?\\b|moderada\\s?(reducao)?\\s?(luminal)?|discreta\\b|(irregularidades?\\s?(pariet(ais|al)|lumin(al|ais))?)|menor que 50%?|maior que 50%?|entre 50%? e 70%?|acima de 50%?|ao redor de 50%?|cerca de 50%?|em torno de 50%?|acima de 70%?|cerca de 70%?|ao redor de 70%?|em torno de 70%?|reducao luminal critica|estenose critica|ocluid(o|a)|reducao luminal moderada|estenose moderada|grau pelo menos moderado|grau moderado|proxima de 50%?|proximo de 50%?)\")\n",
    "reg_modificador = re.compile(r\"(modificador v|vulnerabilidade|remodelamento positivo|baixa atenuacao|napking ring|anel de guardanapo|spot calcifications|baixa atenuacao|remodelamento arterial positivo)\")\n",
    "reg_stent = re.compile(r\"(stent)\")\n",
    "reg_red_stent = re.compile(r\"(proliferacao neointimal|hiperplasia neointimal|hiperplasia|neointimal)\")\n",
    "reg_enxerto = re.compile(r\"(enxerto)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_documentos = df['texto'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encontra_tags(texto):\n",
    "    \n",
    "    lista_retorno = list()\n",
    "    \n",
    "    for item in reg_vaso.finditer(texto):\n",
    "        lista_retorno.append({\n",
    "            'classe'  : 'vaso',\n",
    "            'termo'   : item.group(),\n",
    "            'inicial' : item.start(),\n",
    "            'final'   : item.end()\n",
    "        })\n",
    "    \n",
    "    for item in reg_trajeto.finditer(texto):\n",
    "        lista_retorno.append({\n",
    "            'classe'  : 'trajeto',\n",
    "            'termo'   : item.group(),\n",
    "            'inicial' : item.start(),\n",
    "            'final'   : item.end()\n",
    "        })\n",
    "        \n",
    "    for item in reg_placa.finditer(texto):\n",
    "        lista_retorno.append({\n",
    "            'classe'  : 'placa',\n",
    "            'termo'   : item.group(),\n",
    "            'inicial' : item.start(),\n",
    "            'final'   : item.end()\n",
    "        })\n",
    "        \n",
    "    for item in reg_desc_placa.finditer(texto):\n",
    "        lista_retorno.append({\n",
    "            'classe'  : 'desc_placa',\n",
    "            'termo'   : item.group(),\n",
    "            'inicial' : item.start(),\n",
    "            'final'   : item.end()\n",
    "        })\n",
    "        \n",
    "    for item in reg_oclusao.finditer(texto):\n",
    "        lista_retorno.append({\n",
    "            'classe'  : 'oclusao',\n",
    "            'termo'   : item.group(),\n",
    "            'inicial' : item.start(),\n",
    "            'final'   : item.end()\n",
    "        })\n",
    "        \n",
    "    for item in reg_modificador.finditer(texto):\n",
    "        lista_retorno.append({\n",
    "            'classe'  : 'modificador',\n",
    "            'termo'   : item.group(),\n",
    "            'inicial' : item.start(),\n",
    "            'final'   : item.end()\n",
    "        })\n",
    "        \n",
    "    for item in reg_stent.finditer(texto):\n",
    "        lista_retorno.append({\n",
    "            'classe'  : 'stent',\n",
    "            'termo'   : item.group(),\n",
    "            'inicial' : item.start(),\n",
    "            'final'   : item.end()\n",
    "        })\n",
    "        \n",
    "    for item in reg_red_stent.finditer(texto):\n",
    "        lista_retorno.append({\n",
    "            'classe'  : 'red_stent',\n",
    "            'termo'   : item.group(),\n",
    "            'inicial' : item.start(),\n",
    "            'final'   : item.end()\n",
    "        })\n",
    "        \n",
    "    for item in reg_enxerto.finditer(texto):\n",
    "        lista_retorno.append({\n",
    "            'classe'  : 'enxerto',\n",
    "            'termo'   : item.group(),\n",
    "            'inicial' : item.start(),\n",
    "            'final'   : item.end()\n",
    "        })\n",
    "\n",
    "    return sorted(lista_retorno, key = lambda x : x['inicial'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_texto(texto, lista_tags, indice):\n",
    "    \n",
    "    lista_retorno = list()\n",
    "    lista_tmp = list()\n",
    "    \n",
    "    tamanho_texto = len(texto)\n",
    "    tamanho_lista = len(lista_tags)\n",
    "    \n",
    "    ultima_pos = 0\n",
    "    \n",
    "    for index, achado in enumerate(lista_tags):\n",
    "        \n",
    "        if achado['inicial'] != 0 and index == 0:\n",
    "            lista_tmp.append((texto[0:achado['inicial']], 'O'))\n",
    "            ultima_pos = achado['inicial']\n",
    "\n",
    "        if ultima_pos != achado['inicial']:\n",
    "            lista_tmp.append((texto[ultima_pos:achado['inicial']], 'O'))\n",
    "            \n",
    "        lista_tmp.append((texto[achado['inicial']:achado['final']], achado['classe']))\n",
    "        ultima_pos = achado['final']\n",
    "            \n",
    "        if index + 1 == tamanho_lista:\n",
    "            lista_tmp.append((texto[ultima_pos:], 'O'))\n",
    "        \n",
    "    for item in lista_tmp:\n",
    "        tag_atual = item[1]\n",
    "        for palavra in item[0].split(' '):\n",
    "            if palavra == '':\n",
    "                continue\n",
    "            lista_retorno.append({\n",
    "                'identificador' : indice,\n",
    "                'palavra'       : palavra,\n",
    "                'tag'           : tag_atual\n",
    "            }) \n",
    "    \n",
    "    return lista_retorno\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1\n",
    "lista_resultante = list()\n",
    "\n",
    "for documento in lista_documentos:\n",
    "    lista_tags_documento = encontra_tags(documento)\n",
    "    lista_resultante.extend(parse_texto(documento, lista_tags_documento, index))\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_para_nn = pd.DataFrame(lista_resultante)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_para_nn.head(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# data = pd.read_excel(\"new_output.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_para_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data.fillna(method=\"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f'Total de documentos na base: {len(data.identificador.unique())}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(set(data[\"palavra\"].values))\n",
    "words.append(\"ENDPAD\")\n",
    "n_words = len(words)\n",
    "n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = list(set(data[\"tag\"].values))\n",
    "n_tags = len(tags)\n",
    "n_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, t) for w, t in zip(s[\"palavra\"].values.tolist(),\n",
    "                                                     s[\"tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"identificador\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[\"identificador\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getter = SentenceGetter(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = getter.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = getter.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 300\n",
    "word2idx = {w: i for i, w in enumerate(words)}\n",
    "tag2idx = {t: i for i, t in enumerate(tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids2word = {i: w for w, i in word2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "X = [[word2idx[w[0]] for w in s] for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx[\"ENDPAD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value=word2idx[\"ENDPAD\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx['ENDPAD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [[tag2idx[w[1]] for w in s] for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag2idx[\"O\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_documentos[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [to_categorical(i, num_classes=n_tags) for i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste = y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.1, random_state=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BI LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape=(max_len,))\n",
    "model = Embedding(input_dim=n_words, output_dim=32, input_length=max_len)(input)\n",
    "model = Dropout(0.1)(model)\n",
    "model = Bidirectional(LSTM(units=64, return_sequences=True, recurrent_dropout=0.1))(model)\n",
    "out = TimeDistributed(Dense(n_tags, activation=\"softmax\"))(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_tr, np.array(y_tr), batch_size=32, epochs=15, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model.predict(X_te, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2tag = {i: w for w, i in tag2idx.items()}\n",
    "\n",
    "def pred2label(pred):\n",
    "    out = []\n",
    "    for pred_i in pred:\n",
    "        out_i = []\n",
    "        for p in pred_i:\n",
    "            p_i = np.argmax(p)\n",
    "            out_i.append(idx2tag[p_i].replace(\"ENDPAD\", \"O\"))\n",
    "        out.append(out_i)\n",
    "    return out\n",
    "    \n",
    "pred_labels = pred2label(test_pred)\n",
    "test_labels = pred2label(y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_te[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruir_texto(x, pred, y):\n",
    "    out_lista = list()\n",
    "    for index, item in enumerate(x):\n",
    "        out_lista.append((ids2word.get(item, None), pred[index], y[index]))\n",
    "    return out_lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruir_texto(X_te[1], pred_labels[1], test_labels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_labels, pred_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
